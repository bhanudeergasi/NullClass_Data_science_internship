{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhanudeergasi/NullClass_Data_science_internship/blob/main/model_training1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7M8ogWy19WHO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M8ogWy19WHO",
        "outputId": "e5acbf5a-2c40-4195-e1da-d2b5e09944bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_BN-D07rfXHQ",
      "metadata": {
        "id": "_BN-D07rfXHQ"
      },
      "source": [
        "# # Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IfA1cD4Rdl6w",
      "metadata": {
        "id": "IfA1cD4Rdl6w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0H7ziRuIAa9M",
      "metadata": {
        "id": "0H7ziRuIAa9M"
      },
      "outputs": [],
      "source": [
        "project_path = '/content/drive/MyDrive/TASK1'  # Change if your folder is named differently"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g5rJuexpLZ3Z",
      "metadata": {
        "id": "g5rJuexpLZ3Z"
      },
      "source": [
        " Data Loading and Initial Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gBs2aW7ddmXQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBs2aW7ddmXQ",
        "outputId": "b42bbb4a-b675-47cc-dde4-dc81bce054da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: One class has fewer instances than the desired sample size per class. Using all available instances from the smaller class.\n",
            "Sentiment distribution in sampled and cleaned dataset (Balanced):\n",
            "sentiment\n",
            "0    190\n",
            "1    190\n",
            "Name: count, dtype: Int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the dataset from CSV\n",
        "# Use on_bad_lines='skip' to handle potential parsing errors and quoting=3 for QUOTE_NONE\n",
        "df = pd.read_csv(f'{project_path}/IMDB Dataset.csv', on_bad_lines='skip', quoting=3)\n",
        "\n",
        "\n",
        "# Drop empty/null reviews and empty strings first from the full dataset\n",
        "df = df[df['review'].notnull()]\n",
        "df = df[df['review'].astype(str).str.strip() != '']\n",
        "\n",
        "# Encode the sentiment labels for the cleaned full dataframe\n",
        "df['sentiment'] = pd.to_numeric(df['sentiment'].map({'positive': 1, 'negative': 0}), errors='coerce').astype('Int64').fillna(0)\n",
        "\n",
        "# Separate positive and negative reviews\n",
        "positive_df = df[df['sentiment'] == 1]\n",
        "negative_df = df[df['sentiment'] == 0]\n",
        "\n",
        "# Sample from the larger class to match the size of the smaller class, or sample a fixed number from each\n",
        "# Let's aim for a balanced sample, e.g., 500 positive and 500 negative, totaling 1000\n",
        "sample_size_per_class = 500 # Define sample size per class\n",
        "if len(positive_df) >= sample_size_per_class and len(negative_df) >= sample_size_per_class:\n",
        "    sampled_positive = positive_df.sample(n=sample_size_per_class, random_state=42)\n",
        "    sampled_negative = negative_df.sample(n=sample_size_per_class, random_state=42)\n",
        "    sampled_df = pd.concat([sampled_positive, sampled_negative]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "else:\n",
        "    # Handle case where one class has fewer than sample_size_per_class instances\n",
        "    print(\"Warning: One class has fewer instances than the desired sample size per class. Using all available instances from the smaller class.\")\n",
        "    min_class_size = min(len(positive_df), len(negative_df))\n",
        "    sampled_positive = positive_df.sample(n=min_class_size, random_state=42)\n",
        "    sampled_negative = negative_df.sample(n=min_class_size, random_state=42)\n",
        "    sampled_df = pd.concat([sampled_positive, sampled_negative]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Print value counts for the sampled and cleaned dataframe\n",
        "print(\"Sentiment distribution in sampled and cleaned dataset (Balanced):\")\n",
        "print(sampled_df['sentiment'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RcgwDzJ5f43a",
      "metadata": {
        "id": "RcgwDzJ5f43a"
      },
      "source": [
        "Tokenization and Dataset Creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RZsIzLPUdmvT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321,
          "referenced_widgets": [
            "cff31b316af04ffeb539493c731be333",
            "f83cfab2340e4e7c85d3ecca574b5e68",
            "5210cbac4cd94b5684dbb43eea2cdd27",
            "57cfd3edd0f74031bd1178738d331197",
            "a47c66744785401e99dd2292c90d89ca",
            "ddf52f33cde8458f845ca0751f84911e",
            "58a949e5020940019dbf333ba0682a3c",
            "95036fde2e7041efb444b22af880bf79",
            "06c86aac8c7a40ad91460c6b197a1df8",
            "124b45afe29042c688d9ec0a99683a71",
            "3a371b6cdc654fa4bb46f2ecafab184b",
            "0847beb276324b21828b09aa082f1cc3",
            "ea24d4971ee243d5855888c68e733b7c",
            "81d3f152749a47f6ac0392e983592179",
            "1bbf3811f25842c892d3f39b82c777bd",
            "e015d470c3554427ba704fb65b154c0e",
            "71e3dc8e433f4a2c98941c73f2393e9a",
            "dc39e3c8e6b44fee8135029eb5e33fcf",
            "e05de4dd9c544ed191840975ccfcb2cb",
            "4ab8274ad959493cabadeaad23b674cd",
            "667e676c739d42428c34c45b60a40e70",
            "109448f454934f8897733a29ca68a1dc",
            "ad0693dab8e44fd8bad458e2d032dbed",
            "c38235343c0c4f73a713990325bbc7c7",
            "1e094f4c672c46bfbcdda5f12509bccc",
            "6b7b3586953841c6a57f0dbaee6d2f4d",
            "ef284a02748e4c2294814488e4e11078",
            "ae311a050b004823855cbcff0b64283d",
            "f4d76722ff1241ae90bacf8a74c0769f",
            "efb125816ff947c18411ea22b8ad7ee2",
            "00c6f34f30134622b72090882e495c39",
            "84232ad979994e5e9eee6d2d17703fe2",
            "7fbf1d0daeea4275916dd6ce9b5f4b88",
            "96247e848f4d407bb387f485de4b7cb5",
            "405b3c7079354236adbb8aed4fc450d6",
            "79e9e4de8c2946f3b1d63c945709e8ab",
            "bc04bfe2391048a791e370d6301466a1",
            "143c2fc2903b45a68447c523e62e73d2",
            "94697cfc2c284db2b673409f0382eeb8",
            "dca53c05824b4758abaf6435e0a1d519",
            "8b40b07c93814f6eaae010c2479f9cab",
            "04cf1781fd2347698b6965dcc1cd3ce2",
            "e3df56f5a68e4e42b4716ce09444efbd",
            "0559559f0a9c4145ad830d7b3748f4de"
          ]
        },
        "id": "RZsIzLPUdmvT",
        "outputId": "1752f776-5b88-4c5f-a9f3-17425c8a27c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cff31b316af04ffeb539493c731be333",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0847beb276324b21828b09aa082f1cc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad0693dab8e44fd8bad458e2d032dbed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "96247e848f4d407bb387f485de4b7cb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of input_ids tensor: torch.Size([380, 128])\n",
            "Shape of attention_mask tensor: torch.Size([380, 128])\n",
            "Shape of labels tensor: torch.Size([380])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the reviews from the sampled DataFrame\n",
        "tokens = tokenizer(\n",
        "    sampled_df['review'].tolist(), # Use review column from sampled_df\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=128, # Keeping max_length consistent for now\n",
        "    return_tensors='pt' # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "# Get labels from the sampled_df as a PyTorch tensor\n",
        "# The sentiment column is now guaranteed to have integer values (0 or 1) after balancing\n",
        "labels = torch.tensor(sampled_df['sentiment'].values.astype('int64'))\n",
        "\n",
        "# Print shapes to confirm data is ready\n",
        "print(\"Shape of input_ids tensor:\", tokens['input_ids'].shape)\n",
        "print(\"Shape of attention_mask tensor:\", tokens['attention_mask'].shape)\n",
        "print(\"Shape of labels tensor:\", labels.shape)\n",
        "\n",
        "\n",
        "# Create a custom Dataset class\n",
        "class IMDBDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get a single item (input_ids, attention_mask)\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        # Get the corresponding label and convert to torch.long\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        # The number of items in the dataset is the number of labels\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k2PevTyBLxbZ",
      "metadata": {
        "id": "k2PevTyBLxbZ"
      },
      "source": [
        "Train Test split (Split tokens and label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s-ugUb9NLvJe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-ugUb9NLvJe",
        "outputId": "88473b0e-147a-4446-a559-c565bba3042f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset size: 304\n",
            "Validation dataset size: 76\n",
            "\n",
            "Sentiment distribution in training dataset:\n",
            "1    152\n",
            "0    152\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sentiment distribution in validation dataset:\n",
            "1    38\n",
            "0    38\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-8e2ec00a1b7f>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Split based on indices to ensure corresponding inputs and masks are split together\n",
        "import numpy as np # Import numpy if not already imported\n",
        "\n",
        "# Get indices for splitting\n",
        "train_idx, val_idx = train_test_split(np.arange(len(labels)), test_size=0.2, random_state=42, stratify=labels) # --- Fix 2: Add stratify=labels for stratified split ---\n",
        "\n",
        "# Use indices to create training and validation datasets\n",
        "train_dataset = IMDBDataset(\n",
        "    {key: tokens[key][train_idx] for key in tokens.keys()}, # Select token data using train_idx\n",
        "    labels[train_idx] # Select labels using train_idx\n",
        ")\n",
        "val_dataset = IMDBDataset(\n",
        "    {key: tokens[key][val_idx] for key in tokens.keys()}, # Select token data using val_idx\n",
        "    labels[val_idx] # Select labels using val_idx\n",
        ")\n",
        "\n",
        "\n",
        "# Print dataset sizes to verify the split\n",
        "print(\"Training dataset size:\", len(train_dataset))\n",
        "print(\"Validation dataset size:\", len(val_dataset))\n",
        "\n",
        "# Print sentiment distribution in train and validation sets after stratified split\n",
        "print(\"\\nSentiment distribution in training dataset:\")\n",
        "train_labels_list = [train_dataset[i]['labels'].item() for i in range(len(train_dataset))]\n",
        "print(pd.Series(train_labels_list).value_counts())\n",
        "\n",
        "print(\"\\nSentiment distribution in validation dataset:\")\n",
        "val_labels_list = [val_dataset[i]['labels'].item() for i in range(len(val_dataset))]\n",
        "print(pd.Series(val_labels_list).value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vWHzgnUBL6r9",
      "metadata": {
        "id": "vWHzgnUBL6r9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ojaACjuRL8YP",
      "metadata": {
        "id": "ojaACjuRL8YP"
      },
      "source": [
        "Load the BERT model for sequence classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1uRaDh-JjO7p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "27615157f9db40e882420c2ec5f42902",
            "dbb4ea0911124ae4b77f0fc55b80b034",
            "441510f2b39a43a2a1e27940c234f036",
            "6d7a44a546a640a7949fa071874bda2c",
            "77021aa490fa444d8bec0896f26ab836",
            "7f185826786b47e6b4aee636487a90d2",
            "3cc51b632ee24345b1ca30807c9553c0",
            "b51d8be483f84a6395d7068762cd0a99",
            "25378b44471a43909674b23ea2840b03",
            "cd5e1f58aa724cebbcb2274e41f7cbf4",
            "19625a8ffdb641c5a953e1db72d3bfa5"
          ]
        },
        "id": "1uRaDh-JjO7p",
        "outputId": "f0acd7e5-5769-4417-957f-d719dcd2a737"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27615157f9db40e882420c2ec5f42902",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Explicitly set problem_type for binary classification\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, problem_type=\"single_label_classification\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45VVMx0MjRse",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45VVMx0MjRse",
        "outputId": "9cb824f9-a73e-42d4-c00d-845b5b9459e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Computed Class Weights: tensor([1., 1.])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                     classes=np.unique(train_labels_list),\n",
        "                                     y=train_labels_list)\n",
        "weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "print(\"\\nComputed Class Weights:\", weights)\n",
        "\n",
        "# If running on GPU, move weights to GPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "weights = weights.to(device)\n",
        "model.to(device) # Move model to device\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OAwIlo87MVao",
      "metadata": {
        "id": "OAwIlo87MVao"
      },
      "source": [
        "Define Training Arguments\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8SvUVhuFjPqA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SvUVhuFjPqA",
        "outputId": "64ca4ea3-2b70-448d-82fe-533f88f239c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "<ipython-input-12-aebf288af2aa>:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',  # Directory to save results and checkpoints\n",
        "    num_train_epochs=5,  # --- Fix 4: Increased number of training epochs ---\n",
        "    per_device_train_batch_size=8,  # Batch size per GPU/CPU for training\n",
        "    per_device_eval_batch_size=8,  # Batch size per GPU/CPU for evaluation\n",
        "    warmup_steps=500,  # Number of steps for learning rate warmup\n",
        "    weight_decay=0.01,  # Strength of weight decay\n",
        "    logging_dir='./logs',  # Directory for storing logs\n",
        "    logging_steps=10,  # Log training metrics every 10 steps\n",
        "    eval_strategy='epoch', # Evaluate the model at the end of each epoch\n",
        "    save_strategy='epoch', # Save a checkpoint at the end of each epoch\n",
        "    load_best_model_at_end=True, # Load the best model (based on eval_loss) at the end of training\n",
        "    metric_for_best_model='eval_loss', # Metric to monitor for determining the best model\n",
        "    greater_is_better=False # For 'eval_loss', smaller is better\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,  # The BERT model to train\n",
        "    args=training_args,  # The training arguments defined above\n",
        "    train_dataset=train_dataset,  # The dataset for training\n",
        "    eval_dataset=val_dataset,  # The dataset for validation (evaluation during training)\n",
        "    tokenizer=tokenizer,  # The tokenizer (used by the Trainer for potential tokenization if needed, though we pre-tokenized)\n",
        "\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AWkc9uvDjPyf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "AWkc9uvDjPyf",
        "outputId": "d1012c92-030a-4746-ae1a-405b92764527"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting model training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-8e2ec00a1b7f>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='116' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [116/190 21:26 < 13:55, 0.09 it/s, Epoch 3.03/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.658100</td>\n",
              "      <td>0.534939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.492200</td>\n",
              "      <td>0.330041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.392200</td>\n",
              "      <td>0.293305</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-8e2ec00a1b7f>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "<ipython-input-8-8e2ec00a1b7f>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
            "<ipython-input-8-8e2ec00a1b7f>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='190' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [190/190 35:41, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.658100</td>\n",
              "      <td>0.534939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.492200</td>\n",
              "      <td>0.330041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.392200</td>\n",
              "      <td>0.293305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.276100</td>\n",
              "      <td>0.297116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.203300</td>\n",
              "      <td>0.325191</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-8e2ec00a1b7f>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "print(\"Starting model training...\")\n",
        "trainer.train()\n",
        "print(\"Training finished.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L96HaRdmMcGp",
      "metadata": {
        "id": "L96HaRdmMcGp"
      },
      "source": [
        "Saving thr trained Model and tokenzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eABAXPrVjP6O",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "eABAXPrVjP6O",
        "outputId": "f257de43-e1d4-4f23-d71e-1d237c37608f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model and tokenizer...\n",
            "Model and tokenizer saved to ./imdb_model\n",
            "\n",
            "Evaluating the model on the validation set...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-8e2ec00a1b7f>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Save the trained model and tokenizer\n",
        "print(\"Saving model and tokenizer...\")\n",
        "\n",
        "model.save_pretrained(f'{project_path}/imdb_model')\n",
        "tokenizer.save_pretrained(f'{project_path}/imdb_model')\n",
        "\n",
        "print(\"Model and tokenizer saved to ./imdb_model\")\n",
        "\n",
        "# Evaluate the model on the validation dataset\n",
        "print(\"\\nEvaluating the model on the validation set...\")\n",
        "predictions = trainer.predict(val_dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S7UjQe0UjP-Y",
      "metadata": {
        "id": "S7UjQe0UjP-Y"
      },
      "outputs": [],
      "source": [
        "# Get the predicted class IDs (index of the highest logit)\n",
        "pred_labels = predictions.predictions.argmax(-1)\n",
        "\n",
        "# Get the true labels from the validation dataset\n",
        "# We iterate through the val_dataset to get the original labels\n",
        "# val_labels_list was already created after stratified split\n",
        "true_labels = val_labels_list\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AYh5ennXMhHw",
      "metadata": {
        "id": "AYh5ennXMhHw"
      },
      "source": [
        "Printing the evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A6EtJ0J-jQCQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6EtJ0J-jQCQ",
        "outputId": "10a35c72-af31-428d-c76c-90a2949f2b07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluation Metrics:\n",
            "[[30  8]\n",
            " [ 0 38]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.7895    0.8824        38\n",
            "           1     0.8261    1.0000    0.9048        38\n",
            "\n",
            "    accuracy                         0.8947        76\n",
            "   macro avg     0.9130    0.8947    0.8936        76\n",
            "weighted avg     0.9130    0.8947    0.8936        76\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print evaluation metrics\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(confusion_matrix(true_labels, pred_labels))\n",
        "print(classification_report(true_labels, pred_labels, digits=4)) # Use digits for more precision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f742r1r0jQFn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f742r1r0jQFn",
        "outputId": "38a009b4-0f7d-48e2-f32f-badfb64d57bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy score: 0.8947368421052632\n",
            "precision score: 0.8260869565217391\n",
            "recall score: 1.0\n",
            "f1_score: 0.9047619047619048\n"
          ]
        }
      ],
      "source": [
        "# Print individual metrics\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "print(\"accuracy score:\", accuracy_score(true_labels, pred_labels))\n",
        "print(\"precision score:\", precision_score(true_labels, pred_labels))\n",
        "print(\"recall score:\", recall_score(true_labels, pred_labels))\n",
        "print(\"f1_score:\", f1_score(true_labels, pred_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m02fe9KijQIb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m02fe9KijQIb",
        "outputId": "3875a049-b7e3-48c5-fa5e-c17d82009e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sentiment distribution in sampled and cleaned dataset:\n",
            "sentiment\n",
            "0    190\n",
            "1    190\n",
            "Name: count, dtype: Int64\n"
          ]
        }
      ],
      "source": [
        "# Check the sentiment distribution of the original sampled and cleaned data again (optional)\n",
        "print(\"\\nSentiment distribution in sampled and cleaned dataset:\")\n",
        "print(sampled_df['sentiment'].value_counts())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
